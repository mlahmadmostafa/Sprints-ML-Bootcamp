{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=lambda img: tf.image.random_crop(img, size=[32, 32, 3])\n",
    ")\n",
    "\n",
    "# Only normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
    "test_generator = test_datagen.flow(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class ResidualBlock(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        # Adjust shortcut if stride > 1\n",
    "        if stride != 1:\n",
    "            self.shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, use_bias=False)\n",
    "            self.shortcut_bn = layers.BatchNormalization()\n",
    "        else:\n",
    "            self.shortcut = lambda x: x  # Identity shortcut\n",
    "        \n",
    "    def call(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        if hasattr(self, 'shortcut_bn'):  \n",
    "            shortcut = self.shortcut_bn(shortcut)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = layers.Add()([x, shortcut])\n",
    "        return self.relu(x)\n",
    "\n",
    "class ResNet6(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet6, self).__init__()\n",
    "        self.conv = layers.Conv2D(16, 3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.rb1 = ResidualBlock(16)\n",
    "        self.rb2 = ResidualBlock(16)\n",
    "        self.gap = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.rb1(x)\n",
    "        x = self.rb2(x)\n",
    "        x = self.gap(x)\n",
    "        return self.fc(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net6_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           multiple                  432       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  multiple                 64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  multiple                 4736      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  multiple                 4736      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,138\n",
      "Trainable params: 9,978\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_gpu = ResNet6()\n",
    "model_gpu.build(input_shape=(None, 32, 32, 3))\n",
    "\n",
    "model_cpu = ResNet6()\n",
    "model_cpu.build(input_shape=(None, 32, 32, 3))\n",
    "model_cpu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# show tensor devices\n",
    "for tensor in model_gpu.trainable_variables:\n",
    "    print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 232s 148ms/step - loss: 6.5650 - accuracy: 0.1202 - val_loss: 6.5344 - val_accuracy: 0.2619\n",
      "GPU time: 232.0684311389923 seconds\n",
      "1563/1563 [==============================] - 299s 190ms/step - loss: 2.8328 - accuracy: 0.1933 - val_loss: 2.3047 - val_accuracy: 0.1920\n",
      "CPU time: 299.1338429450989 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    gpu_start = time.time()\n",
    "    model_gpu.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_gpu.fit(train_generator, epochs=1, validation_data=test_generator)\n",
    "    gpu_end = time.time()\n",
    "    print(f\"GPU time: {gpu_end - gpu_start} seconds\")\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_start = time.time()\n",
    "    model_cpu.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_cpu.fit(train_generator, epochs=1, validation_data=test_generator)\n",
    "    cpu_end = time.time()\n",
    "    print(f\"CPU time: {cpu_end - cpu_start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " model (ResNet6) is relatively small. For small models, the overhead of transferring data to the GPU and managing GPU resources can sometimes outweigh the benefits of parallel computation. As a result, the GPU might not provide a significant speedup compared to the CPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
