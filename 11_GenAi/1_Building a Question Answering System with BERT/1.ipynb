{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"rajpurkar/squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(ds[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.162159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.392334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  87599.000000\n",
       "mean       3.162159\n",
       "std        3.392334\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        2.000000\n",
       "75%        3.000000\n",
       "max       43.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = pd.DataFrame([len(answer[\"text\"][0].split()) for answer in ds[\"train\"][:][\"answers\"]])\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.5710e+04, 1.0425e+04, 4.3770e+03, 2.3530e+03, 1.4240e+03,\n",
       "        9.8100e+02, 7.4000e+02, 4.8800e+02, 3.8900e+02, 2.8500e+02,\n",
       "        2.8600e+02, 9.6000e+01, 3.4000e+01, 9.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([ 1. ,  3.1,  5.2,  7.3,  9.4, 11.5, 13.6, 15.7, 17.8, 19.9, 22. ,\n",
       "        24.1, 26.2, 28.3, 30.4, 32.5, 34.6, 36.7, 38.8, 40.9, 43. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths[0], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6939fdd70d454e93eb31ca8ded1230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        sequence_ids = tokenized.sequence_ids(i)\n",
    "        sample_idx = sample_mapping[i]\n",
    "        answers = example[\"answers\"][sample_idx]\n",
    "        \n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "            continue\n",
    "\n",
    "        start_char = answers[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "        token_start_index = 0\n",
    "        while sequence_ids[token_start_index] != 1:\n",
    "            token_start_index += 1\n",
    "\n",
    "        token_end_index = len(input_ids) - 1\n",
    "        while sequence_ids[token_end_index] != 1:\n",
    "            token_end_index -= 1\n",
    "\n",
    "        if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                token_start_index += 1\n",
    "            start_positions.append(token_start_index - 1)\n",
    "\n",
    "            while offsets[token_end_index][1] >= end_char:\n",
    "                token_end_index -= 1\n",
    "            end_positions.append(token_end_index + 1)\n",
    "\n",
    "    tokenized[\"start_positions\"] = start_positions\n",
    "    tokenized[\"end_positions\"] = end_positions\n",
    "    return tokenized\n",
    "\n",
    "encoded = ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=ds[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\program_files\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 88524\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 10784\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)  # Set to DEBUG for verbose logs\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"bert-squad/\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=500,\n",
    "    logging_dir=\"logs/\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    report_to=\"tensorboard\",  # Specify 'tensorboard' for TensorBoard\n",
    "    max_grad_norm=1.0,\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded[\"train\"].select(range(20000)),\n",
    "    eval_dataset=encoded[\"validation\"].select(range(4000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afa527f68194c4aae2716c2d7a6c351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.6906, 'grad_norm': 5.816143035888672, 'learning_rate': 4.964e-06, 'epoch': 0.01}\n",
      "{'loss': 5.4943, 'grad_norm': 6.691579341888428, 'learning_rate': 4.924000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 5.3563, 'grad_norm': 6.652472496032715, 'learning_rate': 4.884e-06, 'epoch': 0.02}\n",
      "{'loss': 5.175, 'grad_norm': 6.371222019195557, 'learning_rate': 4.8440000000000005e-06, 'epoch': 0.03}\n",
      "{'loss': 4.9709, 'grad_norm': 5.715554237365723, 'learning_rate': 4.804e-06, 'epoch': 0.04}\n",
      "{'loss': 4.7523, 'grad_norm': 12.519432067871094, 'learning_rate': 4.7640000000000005e-06, 'epoch': 0.05}\n",
      "{'loss': 4.6073, 'grad_norm': 5.671901702880859, 'learning_rate': 4.724e-06, 'epoch': 0.06}\n",
      "{'loss': 4.4784, 'grad_norm': 5.425264835357666, 'learning_rate': 4.684e-06, 'epoch': 0.06}\n",
      "{'loss': 4.4598, 'grad_norm': 6.248517990112305, 'learning_rate': 4.644e-06, 'epoch': 0.07}\n",
      "{'loss': 4.2997, 'grad_norm': 6.079148769378662, 'learning_rate': 4.604e-06, 'epoch': 0.08}\n",
      "{'loss': 4.1835, 'grad_norm': 6.13507604598999, 'learning_rate': 4.564e-06, 'epoch': 0.09}\n",
      "{'loss': 4.1524, 'grad_norm': 6.409627914428711, 'learning_rate': 4.524e-06, 'epoch': 0.1}\n",
      "{'loss': 4.0727, 'grad_norm': 8.17949390411377, 'learning_rate': 4.484000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 3.9863, 'grad_norm': 9.893970489501953, 'learning_rate': 4.444e-06, 'epoch': 0.11}\n",
      "{'loss': 3.7404, 'grad_norm': 6.987003326416016, 'learning_rate': 4.4040000000000005e-06, 'epoch': 0.12}\n",
      "{'loss': 3.8205, 'grad_norm': 8.343378067016602, 'learning_rate': 4.364e-06, 'epoch': 0.13}\n",
      "{'loss': 3.7626, 'grad_norm': 11.310761451721191, 'learning_rate': 4.3240000000000004e-06, 'epoch': 0.14}\n",
      "{'loss': 3.7574, 'grad_norm': 11.25236988067627, 'learning_rate': 4.284e-06, 'epoch': 0.14}\n",
      "{'loss': 3.585, 'grad_norm': 13.829768180847168, 'learning_rate': 4.244e-06, 'epoch': 0.15}\n",
      "{'loss': 3.4673, 'grad_norm': 12.591669082641602, 'learning_rate': 4.208e-06, 'epoch': 0.16}\n",
      "{'loss': 3.4705, 'grad_norm': 10.66836929321289, 'learning_rate': 4.168000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 3.3986, 'grad_norm': 16.008304595947266, 'learning_rate': 4.128e-06, 'epoch': 0.18}\n",
      "{'loss': 3.1692, 'grad_norm': 16.009607315063477, 'learning_rate': 4.0880000000000005e-06, 'epoch': 0.18}\n",
      "{'loss': 3.1059, 'grad_norm': 22.25448989868164, 'learning_rate': 4.048e-06, 'epoch': 0.19}\n",
      "{'loss': 3.1021, 'grad_norm': 14.294631004333496, 'learning_rate': 4.008e-06, 'epoch': 0.2}\n",
      "{'loss': 3.059, 'grad_norm': 25.291574478149414, 'learning_rate': 3.968e-06, 'epoch': 0.21}\n",
      "{'loss': 3.1505, 'grad_norm': 17.297256469726562, 'learning_rate': 3.928e-06, 'epoch': 0.22}\n",
      "{'loss': 3.0475, 'grad_norm': 22.687671661376953, 'learning_rate': 3.888e-06, 'epoch': 0.22}\n",
      "{'loss': 3.0394, 'grad_norm': 25.335657119750977, 'learning_rate': 3.848e-06, 'epoch': 0.23}\n",
      "{'loss': 3.0894, 'grad_norm': 19.862308502197266, 'learning_rate': 3.8080000000000006e-06, 'epoch': 0.24}\n",
      "{'loss': 3.0422, 'grad_norm': 22.572551727294922, 'learning_rate': 3.7680000000000006e-06, 'epoch': 0.25}\n",
      "{'loss': 2.9615, 'grad_norm': 15.314913749694824, 'learning_rate': 3.7280000000000006e-06, 'epoch': 0.26}\n",
      "{'loss': 2.9929, 'grad_norm': 21.469938278198242, 'learning_rate': 3.692e-06, 'epoch': 0.26}\n",
      "{'loss': 2.8228, 'grad_norm': 18.90927505493164, 'learning_rate': 3.6520000000000004e-06, 'epoch': 0.27}\n",
      "{'loss': 2.8782, 'grad_norm': 17.62380027770996, 'learning_rate': 3.6120000000000003e-06, 'epoch': 0.28}\n",
      "{'loss': 2.9145, 'grad_norm': 17.5576229095459, 'learning_rate': 3.5720000000000003e-06, 'epoch': 0.29}\n",
      "{'loss': 2.8316, 'grad_norm': 15.418899536132812, 'learning_rate': 3.5320000000000002e-06, 'epoch': 0.3}\n",
      "{'loss': 2.6703, 'grad_norm': 17.5058536529541, 'learning_rate': 3.492e-06, 'epoch': 0.3}\n",
      "{'loss': 2.8027, 'grad_norm': 24.04662322998047, 'learning_rate': 3.452e-06, 'epoch': 0.31}\n",
      "{'loss': 2.6677, 'grad_norm': 21.483089447021484, 'learning_rate': 3.412e-06, 'epoch': 0.32}\n",
      "{'loss': 2.8476, 'grad_norm': 21.040407180786133, 'learning_rate': 3.372e-06, 'epoch': 0.33}\n",
      "{'loss': 2.7848, 'grad_norm': 24.30373764038086, 'learning_rate': 3.332e-06, 'epoch': 0.34}\n",
      "{'loss': 2.6426, 'grad_norm': 25.41252899169922, 'learning_rate': 3.292e-06, 'epoch': 0.34}\n",
      "{'loss': 2.6254, 'grad_norm': 23.28862190246582, 'learning_rate': 3.252e-06, 'epoch': 0.35}\n",
      "{'loss': 2.6236, 'grad_norm': 18.823219299316406, 'learning_rate': 3.212e-06, 'epoch': 0.36}\n",
      "{'loss': 2.7175, 'grad_norm': 39.14058303833008, 'learning_rate': 3.172e-06, 'epoch': 0.37}\n",
      "{'loss': 2.559, 'grad_norm': 29.608800888061523, 'learning_rate': 3.132e-06, 'epoch': 0.38}\n",
      "{'loss': 2.6155, 'grad_norm': 23.555341720581055, 'learning_rate': 3.092e-06, 'epoch': 0.38}\n",
      "{'loss': 2.5469, 'grad_norm': 21.70143699645996, 'learning_rate': 3.0520000000000006e-06, 'epoch': 0.39}\n",
      "{'loss': 2.4731, 'grad_norm': 24.989337921142578, 'learning_rate': 3.0120000000000006e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff52cce86d144fbb51907312b38db3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4667153358459473, 'eval_runtime': 917.6264, 'eval_samples_per_second': 4.359, 'eval_steps_per_second': 0.272, 'epoch': 0.4}\n",
      "{'loss': 2.6061, 'grad_norm': 21.133045196533203, 'learning_rate': 2.9720000000000005e-06, 'epoch': 0.41}\n",
      "{'loss': 2.4227, 'grad_norm': 24.208749771118164, 'learning_rate': 2.9320000000000005e-06, 'epoch': 0.42}\n",
      "{'loss': 2.5263, 'grad_norm': 19.10491943359375, 'learning_rate': 2.8920000000000004e-06, 'epoch': 0.42}\n",
      "{'loss': 2.4112, 'grad_norm': 19.734045028686523, 'learning_rate': 2.8520000000000004e-06, 'epoch': 0.43}\n",
      "{'loss': 2.4635, 'grad_norm': 16.35801887512207, 'learning_rate': 2.8120000000000004e-06, 'epoch': 0.44}\n",
      "{'loss': 2.5145, 'grad_norm': 19.287002563476562, 'learning_rate': 2.7720000000000003e-06, 'epoch': 0.45}\n",
      "{'loss': 2.5003, 'grad_norm': 26.03224754333496, 'learning_rate': 2.7320000000000003e-06, 'epoch': 0.46}\n",
      "{'loss': 2.369, 'grad_norm': 18.096752166748047, 'learning_rate': 2.6920000000000002e-06, 'epoch': 0.46}\n",
      "{'loss': 2.3211, 'grad_norm': 19.050445556640625, 'learning_rate': 2.652e-06, 'epoch': 0.47}\n",
      "{'loss': 2.3595, 'grad_norm': 26.768817901611328, 'learning_rate': 2.612e-06, 'epoch': 0.48}\n",
      "{'loss': 2.4915, 'grad_norm': 28.689037322998047, 'learning_rate': 2.572e-06, 'epoch': 0.49}\n",
      "{'loss': 2.5236, 'grad_norm': 23.181503295898438, 'learning_rate': 2.532e-06, 'epoch': 0.5}\n",
      "{'loss': 2.5137, 'grad_norm': 19.534395217895508, 'learning_rate': 2.4920000000000005e-06, 'epoch': 0.5}\n",
      "{'loss': 2.3755, 'grad_norm': 21.439353942871094, 'learning_rate': 2.4520000000000004e-06, 'epoch': 0.51}\n",
      "{'loss': 2.3702, 'grad_norm': 21.124814987182617, 'learning_rate': 2.4120000000000004e-06, 'epoch': 0.52}\n",
      "{'loss': 2.4019, 'grad_norm': 19.399850845336914, 'learning_rate': 2.3720000000000003e-06, 'epoch': 0.53}\n",
      "{'loss': 2.3369, 'grad_norm': 20.19838523864746, 'learning_rate': 2.3320000000000003e-06, 'epoch': 0.54}\n",
      "{'loss': 2.1985, 'grad_norm': 15.459720611572266, 'learning_rate': 2.2920000000000002e-06, 'epoch': 0.54}\n",
      "{'loss': 2.4662, 'grad_norm': 20.153087615966797, 'learning_rate': 2.252e-06, 'epoch': 0.55}\n",
      "{'loss': 2.4113, 'grad_norm': 26.3259220123291, 'learning_rate': 2.212e-06, 'epoch': 0.56}\n",
      "{'loss': 2.3308, 'grad_norm': 24.385496139526367, 'learning_rate': 2.172e-06, 'epoch': 0.57}\n",
      "{'loss': 2.3493, 'grad_norm': 23.907386779785156, 'learning_rate': 2.132e-06, 'epoch': 0.58}\n",
      "{'loss': 2.3869, 'grad_norm': 17.506298065185547, 'learning_rate': 2.092e-06, 'epoch': 0.58}\n",
      "{'loss': 2.3336, 'grad_norm': 23.519031524658203, 'learning_rate': 2.052e-06, 'epoch': 0.59}\n",
      "{'loss': 2.4318, 'grad_norm': 25.685375213623047, 'learning_rate': 2.012e-06, 'epoch': 0.6}\n",
      "{'loss': 2.3244, 'grad_norm': 21.399564743041992, 'learning_rate': 1.972e-06, 'epoch': 0.61}\n",
      "{'loss': 2.1592, 'grad_norm': 17.976909637451172, 'learning_rate': 1.9320000000000003e-06, 'epoch': 0.62}\n",
      "{'loss': 2.5605, 'grad_norm': 22.455455780029297, 'learning_rate': 1.8920000000000003e-06, 'epoch': 0.62}\n",
      "{'loss': 2.4217, 'grad_norm': 20.5994815826416, 'learning_rate': 1.8520000000000002e-06, 'epoch': 0.63}\n",
      "{'loss': 2.2034, 'grad_norm': 22.956649780273438, 'learning_rate': 1.8120000000000002e-06, 'epoch': 0.64}\n",
      "{'loss': 2.1163, 'grad_norm': 27.44979476928711, 'learning_rate': 1.7720000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 2.3367, 'grad_norm': 23.350290298461914, 'learning_rate': 1.732e-06, 'epoch': 0.66}\n",
      "{'loss': 2.2458, 'grad_norm': 24.801555633544922, 'learning_rate': 1.692e-06, 'epoch': 0.66}\n",
      "{'loss': 2.3402, 'grad_norm': 20.392074584960938, 'learning_rate': 1.6520000000000002e-06, 'epoch': 0.67}\n",
      "{'loss': 2.0338, 'grad_norm': 16.827234268188477, 'learning_rate': 1.6120000000000002e-06, 'epoch': 0.68}\n",
      "{'loss': 2.1117, 'grad_norm': 16.710811614990234, 'learning_rate': 1.5720000000000002e-06, 'epoch': 0.69}\n",
      "{'loss': 2.2052, 'grad_norm': 26.452760696411133, 'learning_rate': 1.5320000000000001e-06, 'epoch': 0.7}\n",
      "{'loss': 2.1924, 'grad_norm': 20.08201789855957, 'learning_rate': 1.492e-06, 'epoch': 0.7}\n",
      "{'loss': 2.3487, 'grad_norm': 22.93644142150879, 'learning_rate': 1.452e-06, 'epoch': 0.71}\n",
      "{'loss': 2.1074, 'grad_norm': 19.588916778564453, 'learning_rate': 1.412e-06, 'epoch': 0.72}\n",
      "{'loss': 2.0856, 'grad_norm': 18.95088005065918, 'learning_rate': 1.372e-06, 'epoch': 0.73}\n",
      "{'loss': 2.0945, 'grad_norm': 18.03776741027832, 'learning_rate': 1.3320000000000003e-06, 'epoch': 0.74}\n",
      "{'loss': 2.1468, 'grad_norm': 26.48073959350586, 'learning_rate': 1.2920000000000003e-06, 'epoch': 0.74}\n",
      "{'loss': 2.0893, 'grad_norm': 23.81522560119629, 'learning_rate': 1.2520000000000003e-06, 'epoch': 0.75}\n",
      "{'loss': 2.1842, 'grad_norm': 29.0162410736084, 'learning_rate': 1.2120000000000002e-06, 'epoch': 0.76}\n",
      "{'loss': 2.149, 'grad_norm': 17.640113830566406, 'learning_rate': 1.1720000000000002e-06, 'epoch': 0.77}\n",
      "{'loss': 2.1057, 'grad_norm': 20.11670684814453, 'learning_rate': 1.1320000000000001e-06, 'epoch': 0.78}\n",
      "{'loss': 2.0618, 'grad_norm': 20.04775047302246, 'learning_rate': 1.092e-06, 'epoch': 0.78}\n",
      "{'loss': 2.1421, 'grad_norm': 22.86269760131836, 'learning_rate': 1.052e-06, 'epoch': 0.79}\n",
      "{'loss': 2.3517, 'grad_norm': 25.38190269470215, 'learning_rate': 1.012e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae4ac3bf76748f3adb7cbdfb6bcc1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1524198055267334, 'eval_runtime': 914.9077, 'eval_samples_per_second': 4.372, 'eval_steps_per_second': 0.273, 'epoch': 0.8}\n",
      "{'loss': 2.2126, 'grad_norm': 24.3334903717041, 'learning_rate': 9.72e-07, 'epoch': 0.81}\n",
      "{'loss': 2.1813, 'grad_norm': 19.932424545288086, 'learning_rate': 9.320000000000001e-07, 'epoch': 0.82}\n",
      "{'loss': 2.0285, 'grad_norm': 28.832059860229492, 'learning_rate': 8.920000000000001e-07, 'epoch': 0.82}\n",
      "{'loss': 2.4332, 'grad_norm': 20.56043243408203, 'learning_rate': 8.520000000000001e-07, 'epoch': 0.83}\n",
      "{'loss': 2.0936, 'grad_norm': 25.302898406982422, 'learning_rate': 8.12e-07, 'epoch': 0.84}\n",
      "{'loss': 2.2786, 'grad_norm': 16.42813491821289, 'learning_rate': 7.720000000000001e-07, 'epoch': 0.85}\n",
      "{'loss': 2.1641, 'grad_norm': 21.358415603637695, 'learning_rate': 7.32e-07, 'epoch': 0.86}\n",
      "{'loss': 2.1142, 'grad_norm': 16.416662216186523, 'learning_rate': 6.92e-07, 'epoch': 0.86}\n",
      "{'loss': 2.0578, 'grad_norm': 20.5649356842041, 'learning_rate': 6.52e-07, 'epoch': 0.87}\n",
      "{'loss': 2.0679, 'grad_norm': 20.84090232849121, 'learning_rate': 6.12e-07, 'epoch': 0.88}\n",
      "{'loss': 2.2672, 'grad_norm': 21.535680770874023, 'learning_rate': 5.720000000000001e-07, 'epoch': 0.89}\n",
      "{'loss': 2.1576, 'grad_norm': 23.074922561645508, 'learning_rate': 5.32e-07, 'epoch': 0.9}\n",
      "{'loss': 2.4254, 'grad_norm': 27.44105339050293, 'learning_rate': 4.92e-07, 'epoch': 0.9}\n",
      "{'loss': 2.0236, 'grad_norm': 20.727474212646484, 'learning_rate': 4.52e-07, 'epoch': 0.91}\n",
      "{'loss': 1.9176, 'grad_norm': 20.269533157348633, 'learning_rate': 4.1200000000000004e-07, 'epoch': 0.92}\n",
      "{'loss': 2.2252, 'grad_norm': 16.24169158935547, 'learning_rate': 3.72e-07, 'epoch': 0.93}\n",
      "{'loss': 2.1273, 'grad_norm': 22.440156936645508, 'learning_rate': 3.32e-07, 'epoch': 0.94}\n",
      "{'loss': 2.0127, 'grad_norm': 26.588111877441406, 'learning_rate': 2.92e-07, 'epoch': 0.94}\n",
      "{'loss': 2.1726, 'grad_norm': 23.683740615844727, 'learning_rate': 2.5200000000000003e-07, 'epoch': 0.95}\n",
      "{'loss': 2.0855, 'grad_norm': 20.746660232543945, 'learning_rate': 2.1200000000000002e-07, 'epoch': 0.96}\n",
      "{'loss': 2.2621, 'grad_norm': 16.316381454467773, 'learning_rate': 1.72e-07, 'epoch': 0.97}\n",
      "{'loss': 2.233, 'grad_norm': 33.65322494506836, 'learning_rate': 1.3200000000000002e-07, 'epoch': 0.98}\n",
      "{'loss': 2.204, 'grad_norm': 19.84173011779785, 'learning_rate': 9.2e-08, 'epoch': 0.98}\n",
      "{'loss': 2.1581, 'grad_norm': 19.234403610229492, 'learning_rate': 5.2e-08, 'epoch': 0.99}\n",
      "{'loss': 2.3245, 'grad_norm': 19.63376808166504, 'learning_rate': 1.2e-08, 'epoch': 1.0}\n",
      "{'train_runtime': 45401.1931, 'train_samples_per_second': 0.441, 'train_steps_per_second': 0.028, 'train_loss': 2.753815994262695, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=2.753815994262695, metrics={'train_runtime': 45401.1931, 'train_samples_per_second': 0.441, 'train_steps_per_second': 0.028, 'total_flos': 3919451351040000.0, 'train_loss': 2.753815994262695, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/metrics/evaluate-metric/squad/evaluate-metric/squad.py HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /spaces/evaluate-metric/squad/resolve/v0.4.3/squad.py HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /spaces/evaluate-metric/squad/resolve/main/squad.py HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 2329089782736 on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\75d8b4ad16decd019d81193e848cafd38b43f7c29e53c1370b36245e7ed5bc20.75eb293ae4616c49434e33eee8b713512f402f6972eec62e2a53b88afc40a4cc.py.lock\n",
      "DEBUG:filelock:Lock 2329089782736 acquired on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\75d8b4ad16decd019d81193e848cafd38b43f7c29e53c1370b36245e7ed5bc20.75eb293ae4616c49434e33eee8b713512f402f6972eec62e2a53b88afc40a4cc.py.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /spaces/evaluate-metric/squad/resolve/main/squad.py HTTP/11\" 200 4525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03adf15c6944ff9bdc9676ae715b379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 2329089782736 on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\75d8b4ad16decd019d81193e848cafd38b43f7c29e53c1370b36245e7ed5bc20.75eb293ae4616c49434e33eee8b713512f402f6972eec62e2a53b88afc40a4cc.py.lock\n",
      "DEBUG:filelock:Lock 2329089782736 released on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\75d8b4ad16decd019d81193e848cafd38b43f7c29e53c1370b36245e7ed5bc20.75eb293ae4616c49434e33eee8b713512f402f6972eec62e2a53b88afc40a4cc.py.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /spaces/evaluate-metric/squad/resolve/main/compute_score.py HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 2329092664144 on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\7454265caca9864b599b08661b2f7afd278c2a7de7a35534aced5317e40e46ea.9900c7ed02c782bfb7a87d4eae463bb2043ad38abf7893d46495a3af7d9adf01.py.lock\n",
      "DEBUG:filelock:Lock 2329092664144 acquired on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\7454265caca9864b599b08661b2f7afd278c2a7de7a35534aced5317e40e46ea.9900c7ed02c782bfb7a87d4eae463bb2043ad38abf7893d46495a3af7d9adf01.py.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:filelock:Attempting to release lock 2329092664144 on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\7454265caca9864b599b08661b2f7afd278c2a7de7a35534aced5317e40e46ea.9900c7ed02c782bfb7a87d4eae463bb2043ad38abf7893d46495a3af7d9adf01.py.lock\n",
      "DEBUG:filelock:Lock 2329092664144 released on C:\\Users\\ahmad\\.cache\\huggingface\\evaluate\\downloads\\7454265caca9864b599b08661b2f7afd278c2a7de7a35534aced5317e40e46ea.9900c7ed02c782bfb7a87d4eae463bb2043ad38abf7893d46495a3af7d9adf01.py.lock\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m squad_metric \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msquad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[1;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[1;32m--> 680\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    682\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    683\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hugging Face Hub either.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    684\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubEvaluationModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluate-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\loading.py:489\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    488\u001b[0m imports \u001b[38;5;241m=\u001b[39m get_imports(local_path)\n\u001b[1;32m--> 489\u001b[0m local_imports \u001b[38;5;241m=\u001b[39m \u001b[43m_download_additional_modules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_hub_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[0;32m    496\u001b[0m dynamic_modules_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01melse\u001b[39;00m init_dynamic_modules()\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\loading.py:248\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[1;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong import_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m local_import_path \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sub_directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     local_import_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_import_path, sub_directory)\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\utils\\file_utils.py:175\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(url_or_filename)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_etag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_etag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\utils\\file_utils.py:558\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, download_desc)\u001b[0m\n\u001b[0;32m    556\u001b[0m         ftp_get(url, temp_file)\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 558\u001b[0m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    570\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmove(temp_file\u001b[38;5;241m.\u001b[39mname, cache_path)\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\utils\\file_utils.py:346\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    345\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresume_size\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m416\u001b[39m:  \u001b[38;5;66;03m# Range not satisfiable\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\utils\\file_utils.py:311\u001b[0m, in \u001b[0;36m_request_with_retry\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectTimeout, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tries \u001b[38;5;241m>\u001b[39m max_retries:\n\u001b[1;32m--> 311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out, retrying... [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtries\u001b[38;5;241m/\u001b[39mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\evaluate\\utils\\file_utils.py:307\u001b[0m, in \u001b[0;36m_request_with_retry\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[0;32m    305\u001b[0m tries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectTimeout, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\requests\\adapters.py:682\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    686\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "predictions = trainer.predict(encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_answer(example, start_idx, end_idx, tokenizer):\n",
    "    inputs = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    offsets = inputs[\"offset_mapping\"]\n",
    "    start_char = offsets[start_idx][0]\n",
    "    end_char = offsets[end_idx][1]\n",
    "    return example[\"context\"][start_char:end_char]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "refs = []\n",
    "for i, example in enumerate(ds[\"validation\"]):\n",
    "    start = np.argmax(predictions.predictions[0][i])\n",
    "    end = np.argmax(predictions.predictions[1][i])\n",
    "    answer = get_answer(example, start, end, tokenizer)\n",
    "    preds.append({\"id\": example[\"id\"], \"prediction_text\": answer})\n",
    "    refs.append({\"id\": example[\"id\"], \"answers\": example[\"answers\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = squad_metric.compute(predictions=preds, references=refs)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sample_data = [\n",
    "    {\n",
    "        \"context\": \"The capital of France is Paris. It is known for its art, fashion, and culture.\",\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"answer\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The capital of France is Paris. It is known for its art, fashion, and culture.\",\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"answer\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Python is a high-level programming language used for general-purpose programming.\",\n",
    "        \"question\": \"What is Python used for?\",\n",
    "        \"answer\": \"general-purpose programming\",\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Albert Einstein developed the theory of relativity, which revolutionized modern physics.\",\n",
    "        \"question\": \"Who developed the theory of relativity?\",\n",
    "        \"answer\": \"Albert Einstein\",\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The Eiffel Tower is located in Paris, France. It is a global cultural icon of France.\",\n",
    "        \"question\": \"Where is the Eiffel Tower located?\",\n",
    "        \"answer\": \"Paris, France\",\n",
    "    },\n",
    "]\n",
    "sample_encodings = tokenizer(\n",
    "    [item[\"question\"] for item in sample_data],\n",
    "    [item[\"context\"] for item in sample_data],\n",
    "    truncation=\"only_second\",\n",
    "    padding=\"max_length\",\n",
    "    max_length=384,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**sample_encodings)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Get the predicted start and end token indices\n",
    "start_indices = torch.argmax(start_logits, dim=1)\n",
    "end_indices = torch.argmax(end_logits, dim=1)\n",
    "\n",
    "predicted_answers = []\n",
    "for i, (start_idx, end_idx) in enumerate(zip(start_indices, end_indices)):\n",
    "    start_char = sample_encodings['offset_mapping'][i][start_idx.item()][0]\n",
    "    end_char = sample_encodings['offset_mapping'][i][end_idx.item()][1]\n",
    "    predicted_answer = sample_data[i][\"context\"][start_char:end_char]\n",
    "    predicted_answers.append(predicted_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(sample_data):\n",
    "    print(f\"Context: {item['context']}\")\n",
    "    print(f\"Question: {item['question']}\")\n",
    "    print(f\"Ground Truth Answer: {item['answer']}\")\n",
    "    print(f\"Predicted Answer: {predicted_answers[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
